# 전체 단계 로드맵(요약)

1. **1단계(오늘 제시)**: 웹캠 → 영상서버(수신/중계) → 웹서버(수신/화면표시)까지 “영상 파이프라인” 완성
2. 2단계: 웹서버에서 “버튼 클릭 → 현재 프레임 1장 추론 → JSON 반환 + 오버레이 이미지”
3. 3단계: 실시간 추론(프레임 스킵/리사이즈/비동기) + 다중 클라이언트 대응
4. 4단계: 운영형(큐/브로커, 다중 카메라, 인증, 저장, 장애복구)

---

# 1단계 목표(적당한 범위)

**목표:**

* “영상서버(ingest)”가 **웹캠 영상을 받아서**
* “웹서버(API)”가 **영상서버의 스트림을 받아서**
* 프론트(Svelte)가 **웹서버 스트림을 브라우저에서 재생**한다.

**핵심 포인트:**

* 영상서버는 “카메라 → 프레임 최신값 유지 → MJPEG로 배포”
* 웹서버는 “영상서버 MJPEG를 그대로 프록시(중계)”
  (1단계에서는 객체검출 X. 단, 다음 단계에서 여기 프레임을 바로 YOLO에 넣을 수 있게 구조를 잡음)

---

## 1단계 아키텍처

* **Cam Ingest Server (FastAPI #1, 예: 9001)**

  * 로컬 웹캠(OpenCV) 캡처
  * `/mjpeg` 로 MJPEG 스트림 제공

* **Web Server (FastAPI #2, 예: 8000)**

  * `/video`에서 ingest 서버의 MJPEG를 받아 그대로 중계
  * (추후 `/detect_once`, `/detect_stream` 같은 endpoint를 추가)

* **Frontend (Svelte, 예: 5173)**

  * `<img src="http://localhost:8000/video">` 로 실시간 표시

---

# 1단계 구현

## 0) 준비

```bash
pip install fastapi
pip install "uvicorn[standard]"
```

- "uvicorn[standard]"를 설치하는 이유

`uvicorn`을 설치할 때 `[standard]` 옵션을 붙이는 이유는 한마디로 **"운영 환경(Production)에서 필요한 고성능 의존성 패키지들을 한꺼번에 설치하기 위해서"**입니다.

단순히 `pip install uvicorn`만 실행하면 최소한의 기능만 가진 경량 버전이 설치되지만, `[standard]`를 추가하면 다음과 같은 강력한 도구들이 함께 포함됩니다.

---

### 1. 주요 포함 패키지 및 장점

`[standard]` 옵션을 통해 설치되는 핵심 라이브러리들은 다음과 같습니다.

| 패키지명 | 역할 | 장점 |
| --- | --- | --- |
| **uvloop** | 고성능 이벤트 루프 | 파이썬 기본 `asyncio`보다 훨씬 빠르며, NodeJS나 Go에 비견되는 속도를 제공합니다. (Windows 제외) |
| **httptools** | HTTP 파싱 | C로 작성된 고속 HTTP 파서로, 요청 처리 속도를 극대화합니다. |
| **watchfiles** | 코드 변경 감지 | 개발 모드(`--reload`)에서 파일 변경을 효율적으로 감시합니다. |
| **python-dotenv** | 환경 변수 관리 | `.env` 파일을 자동으로 읽어와 설정 관리를 편하게 해줍니다. |
| **websockets** | WebSocket 지원 | 실시간 양방향 통신을 위한 라이브러리가 포함됩니다. |

---

### 2. 왜 굳이 구분해서 설치하나요?

모든 환경에서 이 패키지들이 필요한 것은 아니기 때문입니다.

* **경량화가 필요한 경우:** Docker 이미지 크기를 최소화해야 하거나, 아주 단순한 테스트용이라면 기본 설치만으로도 충분합니다.
* **플랫폼 호환성:** 예를 들어 `uvloop`은 Windows를 지원하지 않습니다. `[standard]`를 사용하면 설치 시점에 해당 OS에 맞는 최적의 패키지를 알아서 골라 설치해 줍니다.

---

### 3. 요약

> **`pip install uvicorn`**
> * 기본적인 ASGI 서버 기능만 수행.
> * 상대적으로 느림 (순수 파이썬 구현체 위주 사용).
> 
> 

> **`pip install "uvicorn[standard]"`**
> * C로 구현된 고성능 라이브러리 포함.
> * **실제 서비스 운영(Production) 환경**이나 **성능 최적화**가 중요할 때 필수.
> 
> 

---

**💡 팁:** 만약 FastAPI를 사용 중이시라면, FastAPI 자체를 설치할 때 `pip install "fastapi[all]"`을 사용해도 내부에 `uvicorn[standard]`가 포함되어 설치됩니다.
```

---

## 1) 영상서버(웹캠 캡처 + MJPEG)

**cam_server.py**

```python
import cv2
import time
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

app = FastAPI()

cap = cv2.VideoCapture(0)  # 필요 시 1,2 또는 장치 인덱스 변경
if not cap.isOpened():
    raise RuntimeError("웹캠을 열 수 없습니다. 장치 인덱스를 확인하세요.")

def mjpeg_generator():
    # 간단한 FPS 제어(과부하 방지)
    target_fps = 15
    frame_interval = 1.0 / target_fps

    while True:
        t0 = time.time()
        ok, frame = cap.read()
        if not ok:
            time.sleep(0.1)
            continue

        # 필요 시 리사이즈(대역폭/CPU 절감)
        # frame = cv2.resize(frame, (640, 360))

        ok, jpg = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
        if not ok:
            continue

        chunk = jpg.tobytes()
        yield (
            b"--frame\r\n"
            b"Content-Type: image/jpeg\r\n\r\n" + chunk + b"\r\n"
        )

        dt = time.time() - t0
        if dt < frame_interval:
            time.sleep(frame_interval - dt)

@app.get("/mjpeg")
def mjpeg():
    return StreamingResponse(
        mjpeg_generator(),
        media_type="multipart/x-mixed-replace; boundary=frame",
    )
```

실행:

```bash
uvicorn cam_server:app --host 0.0.0.0 --port 9001
```

브라우저에서 확인:

* `http://localhost:9001/mjpeg`

---

## 2) 웹서버(영상서버 스트림을 프록시)

**web_server.py**

```python
import requests
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

app = FastAPI()

CAM_SERVER_MJPEG = "http://localhost:9001/mjpeg"

def proxy_stream():
    # stream=True로 MJPEG를 그대로 받아서 chunk 단위로 전달
    with requests.get(CAM_SERVER_MJPEG, stream=True, timeout=10) as r:
        r.raise_for_status()
        for chunk in r.iter_content(chunk_size=1024):
            if chunk:
                yield chunk

@app.get("/video")
def video():
    return StreamingResponse(
        proxy_stream(),
        media_type="multipart/x-mixed-replace; boundary=frame",
    )
```

실행:

```bash
pip install requests
uvicorn web_server:app --host 0.0.0.0 --port 8000
```

브라우저에서 확인:

* `http://localhost:8000/video`

---

## 3) 프론트엔드(Svelte)

Svelte에서 MJPEG는 보통 `<video>`보다 **`<img>`가 제일 간단**합니다.

**App.svelte**

```svelte
<script>
  const videoUrl = "http://localhost:8000/video";
</script>

<main style="padding:16px;">
  <h1>Live Video (MJPEG Proxy)</h1>
  <img
    src={videoUrl}
    alt="live"
    style="max-width: 100%; border: 1px solid #ccc; border-radius: 8px;"
  />
</main>
```

---

# 1단계 완료 기준(체크리스트)

* [ ] `localhost:9001/mjpeg`에서 웹캠 영상이 나온다
* [ ] `localhost:8000/video`에서 동일 영상이 나온다 (프록시 성공)
* [ ] Svelte 페이지에서 영상이 끊김 없이 나온다

---

# 다음 단계(2단계) 예고

2단계에서는 web_server가 프록시만 하지 말고,

* ingest 서버에서 “최신 프레임 1장”을 가져오거나(혹은 web_server가 직접 프레임을 유지)
* 버튼 클릭 시 YOLO 추론 → JSON + 오버레이 이미지를 반환
  으로 확장합니다.
